<!doctype html><html lang=en class="js csstransforms3d">
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=generator content="Hugo 0.87.0">
<meta name=description content="DLT-META Documentation">
<meta name=author content="Ravi Gawai (Databricks)">
<link rel=icon href=https://databrickslabs.github.io/dlt-meta/images/favicon.png type=image/png>
<title>Metadata Preparation :: DLT-META</title>
<link href=https://databrickslabs.github.io/dlt-meta/css/nucleus.css?1722988832 rel=stylesheet>
<link href=https://databrickslabs.github.io/dlt-meta/css/fontawesome-all.min.css?1722988832 rel=stylesheet>
<link href=https://databrickslabs.github.io/dlt-meta/css/hybrid.css?1722988832 rel=stylesheet>
<link href=https://databrickslabs.github.io/dlt-meta/css/featherlight.min.css?1722988832 rel=stylesheet>
<link href=https://databrickslabs.github.io/dlt-meta/css/perfect-scrollbar.min.css?1722988832 rel=stylesheet>
<link href=https://databrickslabs.github.io/dlt-meta/css/auto-complete.css?1722988832 rel=stylesheet>
<link href=https://databrickslabs.github.io/dlt-meta/css/atom-one-dark-reasonable.css?1722988832 rel=stylesheet>
<link href=https://databrickslabs.github.io/dlt-meta/css/theme.css?1722988832 rel=stylesheet>
<link href=https://databrickslabs.github.io/dlt-meta/css/tabs.css?1722988832 rel=stylesheet>
<link href=https://databrickslabs.github.io/dlt-meta/css/hugo-theme.css?1722988832 rel=stylesheet>
<script src=https://databrickslabs.github.io/dlt-meta/js/jquery-3.3.1.min.js?1722988832></script>
<style>:root #header+#content>#left>#rlblock_left{display:none!important}</style>
<script async defer src=https://buttons.github.io/buttons.js></script>
</head>
<body data-url=https://databrickslabs.github.io/dlt-meta/getting_started/metadatapreperation/>
<nav id=sidebar>
<div id=header-wrapper>
<div id=header>
<a id=logo href=https://databrickslabs.github.io/dlt-meta/>
</a>
</div>
<div class=searchbox>
<label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span>
</div>
<script type=text/javascript src=https://databrickslabs.github.io/dlt-meta/js/lunr.min.js?1722988832></script>
<script type=text/javascript src=https://databrickslabs.github.io/dlt-meta/js/auto-complete.js?1722988832></script>
<script type=text/javascript>var baseurl="https://databrickslabs.github.io/dlt-meta/"</script>
<script type=text/javascript src=https://databrickslabs.github.io/dlt-meta/js/search.js?1722988832></script>
</div>
<section id=homelinks>
<ul>
<li>
<a class=padding href=https://databrickslabs.github.io/dlt-meta/><i class="fas fa-home"></i> Home</a>
</li>
</ul>
</section>
<div class=highlightable>
<ul class=topics>
<li data-nav-id=/getting_started/ title="Getting Started" class="dd-item
parent">
<a href=https://databrickslabs.github.io/dlt-meta/getting_started/>
Getting Started
</a>
<ul>
<li data-nav-id=/getting_started/metadatapreperation/ title="Metadata Preparation" class="dd-item active">
<a href=https://databrickslabs.github.io/dlt-meta/getting_started/metadatapreperation/>
Metadata Preparation
</a>
</li>
<li data-nav-id=/getting_started/dltmeta_cli/ title="DLT-META CLI" class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/getting_started/dltmeta_cli/>
DLT-META CLI
</a>
</li>
<li data-nav-id=/getting_started/dltmeta_manual/ title="DLT-META Manual" class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/getting_started/dltmeta_manual/>
DLT-META Manual
</a>
</li>
</ul>
</li>
<li data-nav-id=/demo/ title=Demo class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/demo/>
Demo
</a>
<ul>
<li data-nav-id=/demo/dais/ title="DAIS DEMO" class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/demo/dais/>
DAIS DEMO
</a>
</li>
<li data-nav-id=/demo/techsummit/ title="Tech Summit DEMO" class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/demo/techsummit/>
Tech Summit DEMO
</a>
</li>
<li data-nav-id=/demo/append_flow_cf/ title="Append FLOW Autoloader Demo" class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/demo/append_flow_cf/>
Append FLOW Autoloader Demo
</a>
</li>
<li data-nav-id=/demo/append_flow_eh/ title="Append FLOW Eventhub Demo" class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/demo/append_flow_eh/>
Append FLOW Eventhub Demo
</a>
</li>
<li data-nav-id=/demo/silver_fanout/ title="Silver Fanout Demo" class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/demo/silver_fanout/>
Silver Fanout Demo
</a>
</li>
</ul>
</li>
<li data-nav-id=/additionals/ title=Additional class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/additionals/>
Additional
</a>
<ul>
<li data-nav-id=/additionals/integration_tests/ title="Integration Tests" class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/additionals/integration_tests/>
Integration Tests
</a>
</li>
</ul>
</li>
<li data-nav-id=/faq/ title="Frequently Asked Questions (FAQs)" class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/faq/>
Frequently Asked Questions (FAQs)
</a>
<ul>
<li data-nav-id=/faq/execution/ title=Execution class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/faq/execution/>
Execution
</a>
</li>
<li data-nav-id=/faq/general/ title=General class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/faq/general/>
General
</a>
</li>
</ul>
</li>
<li data-nav-id=/contributing/ title=Contributing class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/contributing/>
Contributing
</a>
</li>
<li data-nav-id=/releases/ title=Releases class=dd-item>
<a href=https://databrickslabs.github.io/dlt-meta/releases/>
Releases
</a>
</li>
</ul>
<section id=footer>
<center>
<a class=github-button href=https://github.com/databrickslabs/dlt-meta/subscription data-icon=octicon-eye data-show-count=true aria-label="DLT-META on GitHub">Watch</a>
<a class=github-button href=https://github.com/databrickslabs/dlt-meta data-icon=octicon-star data-show-count=true aria-label="Star databricks/dlt-meta on GitHub">Star</a>
<a class=github-button href=https://github.com/databrickslabs/dlt-meta/fork data-icon=octicon-repo-forked data-show-count=true aria-label="Fork DLT-META on GitHub">Fork</a>
<p>A <a href=https://github.com/databrickslabs>Databricks Labs</a> project.</p>
</center>
<script async defer src=https://buttons.github.io/buttons.js></script>
</section>
</div>
</nav>
<section id=body>
<div id=overlay></div>
<div class="padding highlightable">
<div>
<div id=top-bar>
<div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb>
<span id=sidebar-toggle-span>
<a href=# id=sidebar-toggle data-sidebar-toggle>
<i class="fas fa-bars"></i>
</a>
</span>
<span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links>
<a href=https://databrickslabs.github.io/dlt-meta/>DLT-META</a> > <a href=https://databrickslabs.github.io/dlt-meta/getting_started/>Getting Started</a> > Metadata Preparation
</span>
</div>
<div class=progress>
<div class=wrapper>
<nav id=TableOfContents>
<ul>
<li>
<ul>
<li><a href=#directory-structure>Directory structure</a></li>
<li><a href=#onboardingjson-file-structure-examples-autoloaderhttpsgithubcomdatabrickslabsdlt-metablobmainexamplescloudfiles-onboardingtemplate-eventhubhttpsgithubcomdatabrickslabsdlt-metablobmainexampleseventhub-onboardingtemplate-kafkahttpsgithubcomdatabrickslabsdlt-metablobmainexampleskafka-onboardingtemplate->onboarding.json File structure: Examples( <a href=https://github.com/databrickslabs/dlt-meta/blob/main/examples/cloudfiles-onboarding.template>Autoloader</a>, <a href=https://github.com/databrickslabs/dlt-meta/blob/main/examples/eventhub-onboarding.template>Eventhub</a>, <a href=https://github.com/databrickslabs/dlt-meta/blob/main/examples/kafka-onboarding.template>Kafka</a> )</a></li>
<li><a href=#data-quality-rules-file-structureexampleshttpsgithubcomdatabrickslabsdlt-metatreemainexamplesdqe>Data Quality Rules File Structure(<a href=https://github.com/databrickslabs/dlt-meta/tree/main/examples/dqe>Examples</a>)</a></li>
<li><a href=#silver-transformation-file-structureexamplehttpsgithubcomdatabrickslabsdlt-metablobmainexamplessilver_transformationsjson>Silver transformation File Structure(<a href=https://github.com/databrickslabs/dlt-meta/blob/main/examples/silver_transformations.json>Example</a>)</a></li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id=head-tags>
</div>
<div id=body-inner>
<h1>
Metadata Preparation
</h1>
<h3 id=directory-structure>Directory structure</h3>
<pre><code>conf/
    onboarding.json
    silver_transformations.json
    dqe/
        bronze_data_quality_expectations.json
</code></pre><ol>
<li>Create <a href=https://github.com/databrickslabs/dlt-meta/blob/main/demo/conf/onboarding.template>onboarding.json</a></li>
<li>Create <a href=https://github.com/databrickslabs/dlt-meta/blob/main/demo/conf/silver_transformations.json>silver_transformations.json</a></li>
<li>Create data quality rules json&rsquo;s for each entity e.g. <a href=https://github.com/databrickslabs/dlt-meta/tree/main/demo/conf/dqe/>Data Quality Rules</a></li>
</ol>
<p>The <code>onboarding.json</code> file contains links to <a href=https://github.com/databrickslabs/dlt-meta/blob/3555aaa798881a9cfa65f89599f83d22d245d3c8/demo/conf/onboarding.template#L41C1-L42C1>silver_transformations.json</a> and data quality expectation files <a href=https://github.com/databrickslabs/dlt-meta/blob/3555aaa798881a9cfa65f89599f83d22d245d3c8/demo/conf/onboarding.template#L42>dqe</a>.</p>
<h3 id=onboardingjson-file-structure-examples-autoloaderhttpsgithubcomdatabrickslabsdlt-metablobmainexamplescloudfiles-onboardingtemplate-eventhubhttpsgithubcomdatabrickslabsdlt-metablobmainexampleseventhub-onboardingtemplate-kafkahttpsgithubcomdatabrickslabsdlt-metablobmainexampleskafka-onboardingtemplate->onboarding.json File structure: Examples( <a href=https://github.com/databrickslabs/dlt-meta/blob/main/examples/cloudfiles-onboarding.template>Autoloader</a>, <a href=https://github.com/databrickslabs/dlt-meta/blob/main/examples/eventhub-onboarding.template>Eventhub</a>, <a href=https://github.com/databrickslabs/dlt-meta/blob/main/examples/kafka-onboarding.template>Kafka</a> )</h3>
<p><code>env</code> is your environment placeholder e.g <code>dev</code>, <code>prod</code>, <code>stag</code></p>
<table>
<thead>
<tr>
<th style=text-align:center>Field</th>
<th style=text-align:left>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style=text-align:center>data_flow_id</td>
<td style=text-align:left>This is unique identifier for pipeline</td>
</tr>
<tr>
<td style=text-align:center>data_flow_group</td>
<td style=text-align:left>This is group identifier for launching multiple pipelines under single DLT</td>
</tr>
<tr>
<td style=text-align:center>source_format</td>
<td style=text-align:left>Source format e.g <code>cloudFiles</code>, <code>eventhub</code>, <code>kafka</code>, <code>delta</code></td>
</tr>
<tr>
<td style=text-align:center>source_details</td>
<td style=text-align:left>This map Type captures all source details for cloudfiles = <code>source_schema_path</code>, <code>source_path_{env}</code>, <code>source_database</code>, <code>source_metadata</code> For eventhub= <code>source_schema_path</code> , <code>eventhub.accessKeyName</code>, <code>eventhub.accessKeySecretName</code>, <code>eventhub.name</code> , <code>eventhub.secretsScopeName</code> , <code>kafka.sasl.mechanism</code>, <code>kafka.security.protocol</code>, <code>eventhub.namespace</code>, <code>eventhub.port</code>. For Source schema file spark DDL schema format parsing is supported In case of custom schema format then write schema parsing function <code>bronze_schema_mapper(schema_file_path, spark):Schema</code> and provide to <code>OnboardDataflowspec</code> initialization e.g <code>onboardDataFlowSpecs = OnboardDataflowspec(spark, dict_obj,bronze_schema_mapper).onboardDataFlowSpecs()</code>. For cloudFiles option _metadata columns addtiion there is <code>source_metadata</code> tag with attributes: <code>include_autoloader_metadata_column</code> flag (<code>True</code> or <code>False</code> value) will add _metadata column to target bronze dataframe, <code>autoloader_metadata_col_name</code> if this provided then will be used to rename _metadata to this value otherwise default is <code>source_metadata</code>,<code>select_metadata_cols:{key:value}</code> will be used to extract columns from _metadata. key is target dataframe column name and value is expression used to add column from _metadata column</td>
</tr>
<tr>
<td style=text-align:center>bronze_database_{env}</td>
<td style=text-align:left>Delta lake bronze database name.</td>
</tr>
<tr>
<td style=text-align:center>bronze_table</td>
<td style=text-align:left>Delta lake bronze table name</td>
</tr>
<tr>
<td style=text-align:center>bronze_reader_options</td>
<td style=text-align:left>Reader options which can be provided to spark reader e.g multiline=true,header=true in json format</td>
</tr>
<tr>
<td style=text-align:center>bronze_parition_columns</td>
<td style=text-align:left>Bronze table partition cols list</td>
</tr>
<tr>
<td style=text-align:center>bronze_cdc_apply_changes</td>
<td style=text-align:left>Bronze cdc apply changes Json</td>
</tr>
<tr>
<td style=text-align:center>bronze_table_path_{env}</td>
<td style=text-align:left>Bronze table storage path.</td>
</tr>
<tr>
<td style=text-align:center>bronze_table_properties</td>
<td style=text-align:left>DLT table properties map. e.g. <code>{"pipelines.autoOptimize.managed": "false" , "pipelines.autoOptimize.zOrderCols": "year,month", "pipelines.reset.allowed": "false" }</code></td>
</tr>
<tr>
<td style=text-align:center>bronze_data_quality_expectations_json</td>
<td style=text-align:left>Bronze table data quality expectations</td>
</tr>
<tr>
<td style=text-align:center>bronze_database_quarantine_{env}</td>
<td style=text-align:left>Bronze database for quarantine data which fails expectations.</td>
</tr>
<tr>
<td style=text-align:center>bronze_quarantine_table Bronze</td>
<td style=text-align:left>Table for quarantine data which fails expectations</td>
</tr>
<tr>
<td style=text-align:center>bronze_quarantine_table_path_{env}</td>
<td style=text-align:left>Bronze database for quarantine data which fails expectations.</td>
</tr>
<tr>
<td style=text-align:center>bronze_quarantine_table_partitions</td>
<td style=text-align:left>Bronze quarantine tables partition cols</td>
</tr>
<tr>
<td style=text-align:center>bronze_quarantine_table_properties</td>
<td style=text-align:left>DLT table properties map. e.g. <code>{"pipelines.autoOptimize.managed": "false" , "pipelines.autoOptimize.zOrderCols": "year,month", "pipelines.reset.allowed": "false" }</code></td>
</tr>
<tr>
<td style=text-align:center>bronze_append_flows</td>
<td style=text-align:left>Bronze table append flows json. e.g.<code>"bronze_append_flows":[{"name":"customer_bronze_flow", "create_streaming_table": false,"source_format": "cloudFiles", "source_details": {"source_database": "APP","source_table":"CUSTOMERS", "source_path_dev": "tests/resources/data/customers", "source_schema_path": "tests/resources/schema/customer_schema.ddl"},"reader_options": {"cloudFiles.format": "json","cloudFiles.inferColumnTypes": "true","cloudFiles.rescuedDataColumn": "_rescued_data"},"once": true}]</code></td>
</tr>
<tr>
<td style=text-align:center>silver_database_{env}</td>
<td style=text-align:left>Silver database name.</td>
</tr>
<tr>
<td style=text-align:center>silver_table</td>
<td style=text-align:left>Silver table name</td>
</tr>
<tr>
<td style=text-align:center>silver_partition_columns</td>
<td style=text-align:left>Silver table partition columns list</td>
</tr>
<tr>
<td style=text-align:center>silver_cdc_apply_changes</td>
<td style=text-align:left>Silver cdc apply changes Json</td>
</tr>
<tr>
<td style=text-align:center>silver_table_path_{env}</td>
<td style=text-align:left>Silver table storage path.</td>
</tr>
<tr>
<td style=text-align:center>silver_table_properties</td>
<td style=text-align:left>DLT table properties map. e.g. <code>{"pipelines.autoOptimize.managed": "false" , "pipelines.autoOptimize.zOrderCols": "year,month", "pipelines.reset.allowed": "false"}</code></td>
</tr>
<tr>
<td style=text-align:center>silver_transformation_json</td>
<td style=text-align:left>Silver table sql transformation json path</td>
</tr>
<tr>
<td style=text-align:center>silver_data_quality_expectations_json_{env}</td>
<td style=text-align:left>Silver table data quality expectations json file path</td>
</tr>
<tr>
<td style=text-align:center>silver_append_flows</td>
<td style=text-align:left>Silver table append flows json. e.g.<code>"silver_append_flows":[{"name":"customer_bronze_flow", "create_streaming_table": false,"source_format": "cloudFiles", "source_details": {"source_database": "APP","source_table":"CUSTOMERS", "source_path_dev": "tests/resources/data/customers", "source_schema_path": "tests/resources/schema/customer_schema.ddl"},"reader_options": {"cloudFiles.format": "json","cloudFiles.inferColumnTypes": "true","cloudFiles.rescuedDataColumn": "_rescued_data"},"once": true}]</code></td>
</tr>
</tbody>
</table>
<h3 id=data-quality-rules-file-structureexampleshttpsgithubcomdatabrickslabsdlt-metatreemainexamplesdqe>Data Quality Rules File Structure(<a href=https://github.com/databrickslabs/dlt-meta/tree/main/examples/dqe>Examples</a>)</h3>
<table>
<thead>
<tr>
<th style=text-align:center>Field</th>
<th style=text-align:left>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style=text-align:center>expect</td>
<td style=text-align:left>Specify multiple data quality sql for each field when records that fail validation should be included in the target dataset</td>
</tr>
<tr>
<td style=text-align:center>expect_or_fail</td>
<td style=text-align:left>Specify multiple data quality sql for each field when records that fail validation should halt pipeline execution</td>
</tr>
<tr>
<td style=text-align:center>expect_or_drop</td>
<td style=text-align:left>Specify multiple data quality sql for each field when records that fail validation should be dropped from the target dataset</td>
</tr>
<tr>
<td style=text-align:center>expect_or_quarantine</td>
<td style=text-align:left>Specify multiple data quality sql for each field when records that fails validation will be dropped from main table and inserted into quarantine table specified in dataflowspec (only applicable for Bronze layer)</td>
</tr>
</tbody>
</table>
<h3 id=silver-transformation-file-structureexamplehttpsgithubcomdatabrickslabsdlt-metablobmainexamplessilver_transformationsjson>Silver transformation File Structure(<a href=https://github.com/databrickslabs/dlt-meta/blob/main/examples/silver_transformations.json>Example</a>)</h3>
<table>
<thead>
<tr>
<th style=text-align:center>Field</th>
<th style=text-align:left>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style=text-align:center>target_table</td>
<td style=text-align:left>Specify target table name : Type String</td>
</tr>
<tr>
<td style=text-align:center>target_partition_cols</td>
<td style=text-align:left>Specify partition columns : Type Array</td>
</tr>
<tr>
<td style=text-align:center>select_exp</td>
<td style=text-align:left>Specify SQL expressions : Type Array</td>
</tr>
<tr>
<td style=text-align:center>where_clause</td>
<td style=text-align:left>Specify filter conditions if you want to prevent certain records from main input : Type Array</td>
</tr>
</tbody>
</table>
<footer class=footline>
</footer>
</div>
</div>
<div id=navigation>
<a class="nav nav-prev" href=https://databrickslabs.github.io/dlt-meta/getting_started/ title="Getting Started"> <i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=https://databrickslabs.github.io/dlt-meta/getting_started/dltmeta_cli/ title="DLT-META CLI" style=margin-right:0><i class="fa fa-chevron-right"></i></a>
</div>
</section>
<div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px>
<div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div>
</div>
<script src=https://databrickslabs.github.io/dlt-meta/js/clipboard.min.js?1722988832></script>
<script src=https://databrickslabs.github.io/dlt-meta/js/perfect-scrollbar.min.js?1722988832></script>
<script src=https://databrickslabs.github.io/dlt-meta/js/perfect-scrollbar.jquery.min.js?1722988832></script>
<script src=https://databrickslabs.github.io/dlt-meta/js/jquery.sticky.js?1722988832></script>
<script src=https://databrickslabs.github.io/dlt-meta/js/featherlight.min.js?1722988832></script>
<script src=https://databrickslabs.github.io/dlt-meta/js/highlight.pack.js?1722988832></script>
<script>hljs.initHighlightingOnLoad()</script>
<script src=https://databrickslabs.github.io/dlt-meta/js/modernizr.custom-3.6.0.js?1722988832></script>
<script src=https://databrickslabs.github.io/dlt-meta/js/learn.js?1722988832></script>
<script src=https://databrickslabs.github.io/dlt-meta/js/hugo-learn.js?1722988832></script>
<script src=https://databrickslabs.github.io/dlt-meta/mermaid/mermaid.js?1722988832></script>
<script>mermaid.initialize({startOnLoad:!0})</script>
</body>
</html>